{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'deepseek-r1:8b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are a helpful assitant. Provide help to the user. Do not overthink. If you do not know the answer, just say so.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d3084f8-2859-46fc-af38-c59062733159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please write a python code that calculates the prime number up to n\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "105d0db3-f807-4e10-a66e-d0d50596677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_ollama(messages):\n",
    "    stream = openai_ollama.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        # response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Alright, I need to come up with a light-hearted joke that's suitable for a room full of computer engineers. Computer engineers are technically trained in both computers and electrical engineering, which means they have a unique rapport with technology, hardware, and maybe even some software.\n",
       "\n",
       "I should keep the joke simple and relatable. Maybe something about their work environment or common experiences. Let's think about everyday situations they face that can be twisted into a joke. perhaps something involving tech support, coding, or computer parts.\n",
       "\n",
       "Maybe something about why a computer engineer always brings a keyboard to parties. Or maybe something play on \"binary\" or \"bits.\" Alternatively, something about Wi-Fi issues or gaming mishaps could resonate well.\n",
       "\n",
       "I should also make sure it's not too long and keeps the audience engaged without being offensive. It needs to have a punchline that's clear and easy to understand, which can be delivered quickly in a Toastmasters speech.\n",
       "\n",
       "Let me brainstorm a few options. First idea: A computer engineer working from home complains about his keyboard because he types with his fingers on the wrong keys. Or another angle: Computer engineers are the only ones who think they havephantom Wi-Fi signal issues.\n",
       "\n",
       "Wait, that might be a good one. It's relatable and plays on something they deal with daily. Also, it ends with a bit of humor about their imaginary problems.\n",
       "\n",
       "Another thought: A computer engineer brings a router to a party because he can't handle the noise without checking signal strength. But I think the first idea is cleaner and more straightforward.\n",
       "\n",
       "So, putting it all together, a joke about constant network issues being a sign of an overthinking engineer looking for phantom connections.\n",
       "</think>\n",
       "\n",
       "A room full of computer engineers chuckled as one joker quipped, \"You know you're in tech support when your imagination is limited to phantom Wi-Fi signals!\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "question = \"\"\"\n",
    "Tell a light-heatred joke for a room of computer engineers\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "stream_ollama(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8837a0-2dee-414d-8ab5-53c0bc9a8441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
